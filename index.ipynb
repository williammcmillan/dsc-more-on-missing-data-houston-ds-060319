{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More On Missing Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've seen various methods of how to deal with missing data, its time to further discuss how to choose and appropriate methodology given a particular scenario. Commonly, many people will immediately turn to imputing the mean or median of a feature with missing values. This can be valid and effective methodology, hence why it is standard, but does have caveats. For example, doing so will reduce the overall variance of your dataset which should be taken into account when performing subsequent analyses or training a machine learning algorithm on the data set.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to: \n",
    "\n",
    "* Consider the impacts of various techniques for dealing with missing data.\n",
    "* Check a dataset for duplicates\n",
    "* Uncover missing values that are not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  PassengerId  Survived Pclass  \\\n",
       "0           0           0.0          1.0       0.0      3   \n",
       "1           1           1.0          2.0       1.0      1   \n",
       "2           2           2.0          3.0       1.0      3   \n",
       "3           3           3.0          4.0       1.0      1   \n",
       "4           4           4.0          5.0       0.0      3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0    1.0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0    1.0   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0    0.0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0    1.0   \n",
       "4                           Allen, Mr. William Henry    male  35.0    0.0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0    0.0         A/5 21171   7.2500   NaN        S  \n",
       "1    0.0          PC 17599  71.2833   C85        C  \n",
       "2    0.0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3    0.0            113803  53.1000  C123        S  \n",
       "4    0.0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df, figsize=(10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Missing Data\n",
    "\n",
    "Typically, the first step in checking for missing data is to simply use the df.info() method. This gives us various information about the columns including their data type and the number of non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "Unnamed: 0     891 non-null int64\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null object\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, Age and Cabin have a substantial amount of missing values, and Embarked has 2 extraneous missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Duplicates\n",
    "\n",
    "While `df.info()` is a good initial spot check for missing values, it may not catch more subtle anomalies in the data such as duplicates. While these values are populated, it is always worrisome if we have observation rows with identical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PassengerId  Survived Pclass                     Name   Sex  \\\n",
       "0         0.0          1.0       0.0      3  Braund, Mr. Owen Harris  male   \n",
       "0         0.0          1.0       0.0      3  Braund, Mr. Owen Harris  male   \n",
       "0         0.0          1.0       0.0      3  Braund, Mr. Owen Harris  male   \n",
       "0         0.0          1.0       0.0      3  Braund, Mr. Owen Harris  male   \n",
       "0         0.0          1.0       0.0      3  Braund, Mr. Owen Harris  male   \n",
       "\n",
       "    Age  SibSp  Parch     Ticket  Fare Cabin Embarked  \n",
       "0  22.0    1.0    0.0  A/5 21171  7.25   NaN        S  \n",
       "0  22.0    1.0    0.0  A/5 21171  7.25   NaN        S  \n",
       "0  22.0    1.0    0.0  A/5 21171  7.25   NaN        S  \n",
       "0  22.0    1.0    0.0  A/5 21171  7.25   NaN        S  \n",
       "0  22.0    1.0    0.0  A/5 21171  7.25   NaN        S  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    "print(len(duplicates))\n",
    "duplicates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if a feature such as PassengerId can be assumed to be unique, we can further check if there are duplicate rows based on a subset of the DataFrame columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>257.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>Rush, Mr. Alfred George John</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113510</td>\n",
       "      <td>12.8750</td>\n",
       "      <td>B79</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>300.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Skoog, Master. Harald</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2671</td>\n",
       "      <td>17.4000</td>\n",
       "      <td>E49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>65.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>Slocovski, Mr. Selman Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>239854</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>B49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>807.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>Glynn, Miss. Mary Agatha</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36866</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>F G63</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>664.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>Sobey, Mr. Samuel James Hayden</td>\n",
       "      <td>male</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2672</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C148</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  PassengerId  Survived Pclass                            Name  \\\n",
       "395       257.0        839.0       0.0      ?    Rush, Mr. Alfred George John   \n",
       "396       300.0        839.0       1.0      2           Skoog, Master. Harald   \n",
       "397        65.0        839.0       0.0      ?   Slocovski, Mr. Selman Francis   \n",
       "398       807.0        839.0       1.0      ?        Glynn, Miss. Mary Agatha   \n",
       "399       664.0        839.0       0.0      ?  Sobey, Mr. Samuel James Hayden   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket      Fare  Cabin Embarked  \n",
       "395    male  47.0    0.0    4.0  113510   12.8750    B79        C  \n",
       "396  female  17.0    5.0    5.0    2671   17.4000    E49      NaN  \n",
       "397    male  47.0    8.0    4.0  239854    7.0500    B49      NaN  \n",
       "398    male  48.0    1.0    0.0   36866    8.6625  F G63        C  \n",
       "399    male  14.5    3.0    4.0    2672  108.9000   C148        S  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.duplicated(subset='PassengerId')]\n",
    "print(len(duplicates))\n",
    "duplicates.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for extraneous values\n",
    "\n",
    "Sometimes, null values are even further hidden within a dataset. For example, sometimes an entry such as `999999` is used for missing values, or an arbitrary date such as `12-01-1970` might be set for unknown dates. In general, doing a quick eyeball and previewing the top occurring values for each feature can help further tease out peculiarities in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 \n",
      " 0.0      0.073329\n",
      "680.0    0.003595\n",
      "816.0    0.003595\n",
      "2.0      0.002876\n",
      "420.0    0.002876\n",
      "Name: Unnamed: 0, dtype: float64 \n",
      "\n",
      "\n",
      "PassengerId \n",
      " 839.0    0.288282\n",
      "1.0      0.072610\n",
      "881.0    0.000719\n",
      "757.0    0.000719\n",
      "195.0    0.000719\n",
      "Name: PassengerId, dtype: float64 \n",
      "\n",
      "\n",
      "Survived \n",
      " 0.0    0.618979\n",
      "1.0    0.381021\n",
      "Name: Survived, dtype: float64 \n",
      "\n",
      "\n",
      "Pclass \n",
      " 3    0.475198\n",
      "1    0.219267\n",
      "2    0.199137\n",
      "?    0.106398\n",
      "Name: Pclass, dtype: float64 \n",
      "\n",
      "\n",
      "Name \n",
      " Braund, Mr. Owen Harris                      0.072610\n",
      "Stone, Mrs. George Nelson (Martha Evelyn)    0.003595\n",
      "Maioni, Miss. Roberta                        0.002876\n",
      "Chapman, Mr. John Henry                      0.002876\n",
      "Butler, Mr. Reginald Fenton                  0.002876\n",
      "Name: Name, dtype: float64 \n",
      "\n",
      "\n",
      "Sex \n",
      " male      0.641265\n",
      "female    0.358735\n",
      "Name: Sex, dtype: float64 \n",
      "\n",
      "\n",
      "Age \n",
      " 22.0    0.106700\n",
      "18.0    0.029777\n",
      "24.0    0.029777\n",
      "25.0    0.023987\n",
      "30.0    0.023160\n",
      "Name: Age, dtype: float64 \n",
      "\n",
      "\n",
      "SibSp \n",
      " 0.0    0.473041\n",
      "1.0    0.263120\n",
      "2.0    0.060388\n",
      "3.0    0.057513\n",
      "8.0    0.055356\n",
      "Name: SibSp, dtype: float64 \n",
      "\n",
      "\n",
      "Parch \n",
      " 0.0    0.595255\n",
      "1.0    0.125090\n",
      "2.0    0.099209\n",
      "4.0    0.051042\n",
      "5.0    0.048167\n",
      "Name: Parch, dtype: float64 \n",
      "\n",
      "\n",
      "Ticket \n",
      " A/5 21171    0.072610\n",
      "CA 2144      0.005751\n",
      "CA. 2343     0.005751\n",
      "113781       0.005751\n",
      "347082       0.005751\n",
      "Name: Ticket, dtype: float64 \n",
      "\n",
      "\n",
      "Fare \n",
      " 7.2500     0.082674\n",
      "8.0500     0.033070\n",
      "13.0000    0.031632\n",
      "7.8958     0.029475\n",
      "7.7500     0.026600\n",
      "Name: Fare, dtype: float64 \n",
      "\n",
      "\n",
      "Cabin \n",
      " A20            0.013289\n",
      "B41            0.013289\n",
      "E121           0.013289\n",
      "C23 C25 C27    0.011628\n",
      "C83            0.011628\n",
      "Name: Cabin, dtype: float64 \n",
      "\n",
      "\n",
      "Embarked \n",
      " S    0.643910\n",
      "C    0.221102\n",
      "Q    0.134988\n",
      "Name: Embarked, dtype: float64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col, '\\n', df[col].value_counts(normalize=True).head(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we've uncovered another case of missing data that did not show up before! The Pclass feature has `?` for roughly 10% of the entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Methodology\n",
    "\n",
    "Now that you have some ideas of various methods for dealing with missing data, how do you choose which to use? The answer will depend on the scenario and specifics to the application itself. As a general rule of thumb, we tend towards imputing values rather than dropping them, as we wish to use as much information as possible. That said, larger gaps where data is missing can pose more substantial problems, and thereby warrant alternative approaches. We'll take a look at specific cases below in more detail, but here's a quick table of your options.\n",
    "\n",
    "|         | Continuous          | Categorical  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| Delete      | Delete Rows (observations) <br> Delete column (entire variable)| Delete Rows (observations) <br> Delete column (entire variable)|\n",
    "| Replace | replace using median/mean | replace using mode\n",
    "| Keep | keep as NA (not possible for many ML algorithms) | NA category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Values\n",
    "\n",
    "Imputing values is often a go to option when dealing with missing data. For example, if we are building a machine learning model with the data, many algorithms cannot handle missing values. By imputing data, we still get to use the full extent of the data at hand without having to throw away data, which, as you know, is an easy option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1391 entries, 0 to 399\n",
      "Data columns (total 13 columns):\n",
      "Unnamed: 0     1391 non-null float64\n",
      "PassengerId    1391 non-null float64\n",
      "Survived       1391 non-null float64\n",
      "Pclass         1391 non-null object\n",
      "Name           1391 non-null object\n",
      "Sex            1391 non-null object\n",
      "Age            1209 non-null float64\n",
      "SibSp          1391 non-null float64\n",
      "Parch          1391 non-null float64\n",
      "Ticket         1391 non-null object\n",
      "Fare           1391 non-null float64\n",
      "Cabin          602 non-null object\n",
      "Embarked       1289 non-null object\n",
      "dtypes: float64(7), object(6)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerations When Imputing\n",
    "\n",
    "When imputing missing values, keep in mind that you are influencing the distribution of this variable. For example, if you impute the mean, you will reduce the variance of that feature. \n",
    "\n",
    "## When to Drop Rows\n",
    "\n",
    "\n",
    "Dropping rows is an appropriate choice if there are very few missing values to start with. After all, we do not wish to throw away troves of data if we have it, so cases in which there are larger occurrences of missing values, dropping all occurrences is typically inadvisable.\n",
    "\n",
    "## When to Drop Columns\n",
    "\n",
    "Dropping columns is typically a last case resort. That said, if a feature does not add predictive value to the machine learning algorithm driving your application, dropping said feature has no cost.\n",
    "\n",
    "A few simple lines such as this can easily subset your DataFrame:  \n",
    "~~~\n",
    "cols_to_remove = ['col1', 'col2']\n",
    "cols = [col for col in df.columns if col not in cols_to_remove]\n",
    "subset = df[cols]\n",
    "~~~\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lesson, we took a look at methods for identifying duplicate data as well as missing data that is not null, but filled with a placeholder value (such as ?). We also began to discuss considerations when dealing with missing data, which you yourself will further grapple with in the upcoming lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
